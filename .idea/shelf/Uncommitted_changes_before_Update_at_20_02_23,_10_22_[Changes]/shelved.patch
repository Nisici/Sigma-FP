Index: src/fast-sigma-FP.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#! /usr/bin/env python\n\nimport os\nimport sys\nimport time\n\nimport cv2\nimport random\nimport numpy as np\nfrom math import pi\nimport open3d as o3d\nfrom copy import deepcopy\n\nimport rospy\nimport tf2_ros\nimport message_filters\nfrom cv_bridge import CvBridge, CvBridgeError\n\nfrom sklearn.cluster import DBSCAN\n\nfrom std_msgs.msg import Header, String, ColorRGBA\nfrom geometry_msgs.msg import PoseWithCovarianceStamped, Transform, TransformStamped, Quaternion\nfrom sensor_msgs.msg import Image, CompressedImage, PointCloud2\nfrom detectron2_ros.msg import ResultWithWalls\nfrom visualization_msgs.msg import MarkerArray\nfrom sigmafp.msg import WallMeshArray\n\nfrom utils import PlaneManager, Transformations\n\nclass FloorplanReconstruction(object):\n    def __init__(self):\n\n        rospy.logwarn(\"Initializing Sigma-FP: 3D Floorplan Reconstruction\")\n\n        # ROS Parameters\n        self.image_rgb_topic = self.load_param('~topic_cameraRGB', \"ViMantic/virtualCameraRGB\")\n        self.image_depth_topic = self.load_param('~topic_cameraDepth', \"ViMantic/virtualCameraDepth\")\n        self.semantic_topic = self.load_param('~topic_result', 'ViMantic/Detections')\n        self.cnn_topic = self.load_param('~topic_cnn', 'detectron2_ros/result')\n        self.image_toCNN = self.load_param('~topic_republic', 'ViMantic/ToCNN')\n        self.dataset = self.load_param('~dataset', \"RobotAtVirtualHome\")\n        self.debug = self.load_param('~debug', False)\n\n        # Camera Calibration\n        self._width = self.load_param('~image_width', 640)\n        self._height = self.load_param('~image_height', 480)\n        self._cx = self.load_param('~camera_cx', 320)\n        self._cy = self.load_param('~camera_cy', 240)\n        self._fx = self.load_param('~camera_fx', 304.0859)\n        self._fy = self.load_param('~camera_fy', 312.7741)\n        self._depth_range_max = self.load_param('~camera_depth_max_range', 10.0)\n        self._min_reliable_cam_depth = self.load_param('~min_reliable_depth_value', 0.01)\n        self._max_reliable_cam_depth = self.load_param('~max_reliable_depth_value', self._depth_range_max - 0.01)\n\n        # Flow control variables, flags and counters\n        self._publish_rate = 10             # Rate of ROS publishing\n        self._max_tries = 10                # Max tries for the CNN to process an image before skipping the image\n        self._tries = 0                     # Number of current tries to get the CNN available to process the image\n        self._image_counter = 0             # Number of images processed by the CNN\n        self._n_iterations = 0              # Number of iterations of our method\n        self._n_iterations_openings = 0     # Number of tries to detect openings\n        self._flag_processing = False       # Waiting a new input image to process\n        self._flag_cnn = False              # CNN is occupied\n\n        # Timers\n        self._start_time = 0                # Time when the code starts\n        self._total_time = 0                # Time elapsed until now\n        self._time_plane_extraction = 0     # Total time spent in plane extraction\n        self._time_opening_detection = 0    # Total time spent in opening detection\n        self._time_plane_matching = 0       # Total time spent in plane matching\n\n        # Image variables\n        self._last_msg = None               # Last input image received\n        self._last_cnn_result = None        # Last output of the CNN\n        self._image_r = None                # Rows grid (cx - row_idx) / fx\n        self._image_c = None                # Columns grid (cy - column_idx) / fy\n\n        # Parameters and variables of Sigma-FP\n        self._n_points_in_pcd = self.load_param('~points_in_pcd', 6000)  # Number of points in the downgraded point cloud\n        self._min_points_plane = self.load_param('~min_points_plane', 60)  # Minimum number of points to consider a planar patch as a possible wall  # 100\n        self._min_plane_width = self.load_param('~min_plane_width', 0.35)  # Minimum width to accept a planar patch as a possible wall (in meters)\n        self._min_px_opening = self.load_param('~min_px_opening', 7000)  # Minimum number of pixels to consider a region as a opening  # 8000\n        self._bhattacharyya_threshold = self.load_param('~bhattacharyya_threshold', 10)  # Threshold for the statistical distance of Bhattacharyya  # real 7\n        self._euclidean_threshold = self.load_param('~euclidean_threshold', 1.1)  # Threshold for the minimum euclidean distance between walls  # 0.3\n        self._eps_alpha = self.load_param('~eps_alpha', 8.0) * pi / 180.0  # Epsilon for DBSCAN of the azimuth angle of the plane (in radians)  # 1\n        self._eps_beta = self.load_param('~eps_beta', 8.0) * pi / 180.0  # Epsilon for DBSCAN of the elevation angle of the plane (in radians) # 10\n        self._eps_dist = self.load_param('~eps_dist', 0.005)  # Epsilon for DBSCAN of the plane-to-origin distance (in meters)  # real 0.02\n        self._num_walls = 0  # Number of current detected walls\n        self._walls = {}  # Dictionary including the complete information of the current floorplan\n\n        # Transformations\n        self._camera_robot_transform = None     # Relative pose of the camera frame w.r.t. the robot frame\n\n        # Publishers\n        self._pub_processed_image = rospy.Publisher(self.image_toCNN, Image, queue_size=1)\n        self._walls_pub = rospy.Publisher('walls', MarkerArray, queue_size=10)\n        self._pcd_pub = rospy.Publisher('pointcloud_visualization', PointCloud2, queue_size=1)\n        self._unity_pub = rospy.Publisher('wall_mesh', WallMeshArray, queue_size=10)\n\n        # Subscribers\n        rospy.Subscriber(self.cnn_topic, ResultWithWalls, self.callback_new_detection)\n        rospy.Subscriber(\"wallmap_commands\", String, self.callback_commands)\n\n        if self.dataset == \"RobotAtVirtualHome\":\n            sub_rgb_image = message_filters.Subscriber(self.image_rgb_topic, CompressedImage)\n            sub_depth_image = message_filters.Subscriber(self.image_depth_topic, CompressedImage)\n        elif self.dataset == \"Giraff\":\n            sub_rgb_image = message_filters.Subscriber(self.image_rgb_topic, CompressedImage)\n            sub_depth_image = message_filters.Subscriber(self.image_depth_topic, Image)\n        else:\n            sub_rgb_image = message_filters.Subscriber(self.image_rgb_topic, Image)\n            sub_depth_image = message_filters.Subscriber(self.image_depth_topic, Image)\n\n        sub_pose_amcl = message_filters.Subscriber('amcl_pose', PoseWithCovarianceStamped)\n        message_filter = message_filters.ApproximateTimeSynchronizer([sub_depth_image, sub_rgb_image, sub_pose_amcl],\n                                                                     10, 0.1)\n        message_filter.registerCallback(self.callback_synchronize_image)\n\n        # Handlers\n        self._bridge = CvBridge()\n        self._tfBuffer = tf2_ros.Buffer()\n        tf2_ros.TransformListener(self._tfBuffer)\n        self._tr = Transformations()\n        self._pm = PlaneManager(self._height, self._width, self._cx, self._cy, self._fx, self._fy,\n                                self._depth_range_max, self._min_px_opening)\n\n        rospy.logwarn(\"Initialized\")\n\n    ####################################################################################################################\n    ################################################### Node Script ####################################################\n    ####################################################################################################################\n\n    def run(self):\n\n        rate = rospy.Rate(self._publish_rate)\n\n        while not rospy.is_shutdown():\n            # Extracting and projecting detected walls\n            if self._flag_processing and self._flag_cnn:\n\n                # Getting the mask of pixels belonging to walls\n                try:\n                    wall_mask = self._bridge.imgmsg_to_cv2(self._last_cnn_result.walls) == 255\n                except CvBridgeError as e:\n                    print(e)\n                    continue\n\n                # Check if there are pixels belonging to walls in the image\n                if not np.max(np.max(wall_mask)):\n                    self._flag_cnn = False\n                    self._flag_processing = False\n                    continue\n\n                # Obtain 3D coordinates, in meters, of each pixel\n                z = self._last_msg[2] * self._depth_range_max\n                x = self._image_c * z\n                y = self._image_r * z\n\n                time_start = time.time()\n\n                # Create point cloud of walls\n                point_cloud = np.array([z[wall_mask].reshape(-1), x[wall_mask].reshape(-1), y[wall_mask].reshape(-1)]).T\n\n                # Reduce the point cloud to the data in the reliable range of the depth sensor\n                point_cloud = point_cloud[np.logical_and(point_cloud[:, 0] > self._min_reliable_cam_depth,\n                                                         point_cloud[:, 0] < self._max_reliable_cam_depth)].copy()\n\n                if self.dataset == \"Giraff\":\n                    point_cloud = point_cloud[point_cloud[:, 2] < 1.5].copy()\n\n                # Create the point cloud in open3d\n                pcd = o3d.geometry.PointCloud(points=o3d.utility.Vector3dVector(point_cloud))\n\n                # Downsampling point cloud\n                try:\n                    pcd = pcd.uniform_down_sample(int(len(point_cloud) / self._n_points_in_pcd))\n                except:\n                    pass\n\n                pcd_np = np.asarray(pcd.points)\n\n                print(\"Number of points in downsampled pointcloud: {}/{}\".format(pcd_np.shape[0], len(point_cloud)))\n\n                if pcd_np.shape[0] == 0:\n                    self._flag_cnn = False\n                    self._flag_processing = False\n                    continue\n\n                # Obtain mean distance between points in the point cloud\n                # More precise but very time-consuming (Not recommended)\n                #tree = KDTree(pcd_np)\n                #dist, _ = tree.query(pcd_np, k=100)\n                #mean_dist_pcd = np.sum(dist[:, 99]) / dist.shape[0]\n\n                # To avoid high consumption times, please use the following: (Recommended)\n                mean_dist_pcd = 0.1\n\n                # Compute, normalize and orient normals towards camera location\n                pcd.estimate_normals(\n                    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=mean_dist_pcd, max_nn=100))\n                pcd.normalize_normals()\n                pcd.orient_normals_towards_camera_location()\n\n                # Create transform msg from robot to map\n                trans_amcl = TransformStamped()\n                trans_amcl.header = Header(0, rospy.Time(), 'map')\n                trans_amcl.child_frame_id = \"base_link\"\n                trans_amcl.transform = Transform(self._last_msg[5].pose.pose.position,\n                                                 self._last_msg[5].pose.pose.orientation)\n\n                # Obtain transformation matrixes\n                tr_matrix_robot_camera = self._tr.msg_to_se3(self._camera_robot_transform)  # Robot -> Camera\n                tr_matrix_robot_map = self._tr.msg_to_se3(trans_amcl)                       # Robot -> Map\n                tr_matrix_camera_map = np.matmul(tr_matrix_robot_map, tr_matrix_robot_camera)   # Camera -> Map\n                inv_tr_matrix = np.linalg.inv(tr_matrix_camera_map)\n\n                # Obtain point cloud wrt robot frame\n                pcd = pcd.transform(tr_matrix_robot_camera)\n                pcd_np = np.asarray(pcd.points)\n\n                # Obtain point cloud in global coordinates wrt world frame\n                pcd_global = deepcopy(pcd)\n                pcd_global.transform(tr_matrix_robot_map)\n\n                # Debugging: show in rviz the processed point cloud\n                if self.debug:\n                    self._pcd_pub.publish(self._pm.point_cloud_visualization_rviz(pcd_global, self._last_msg[0]))\n\n                # Generate data for clustering: elevation and azimuth angles from normals and distance plane-origin\n                normals = np.array(pcd.normals)\n                alpha = np.arctan2(normals[:, 1], normals[:, 0]).reshape(-1, 1)\n                beta = np.arccos(normals[:, 2]).reshape(-1, 1)\n                distance_to_origin = np.sum(normals * pcd_np, axis=1).reshape(-1, 1)\n                dbscan_data = np.concatenate((alpha, beta, distance_to_origin), axis=1)\n                dbscan_data_scaled = dbscan_data / np.asarray([self._eps_alpha, self._eps_beta, self._eps_dist])\n\n                # DBSCAN Clustering\n                clustering = DBSCAN(eps=1., min_samples=self._min_points_plane).fit(dbscan_data_scaled)\n                labels = clustering.labels_.astype(np.float_)\n                max_label = labels.max()\n\n                # Time for plane extraction\n                self._time_plane_extraction += time.time() - time_start\n\n                # Characterizing each clustered wall by: its Gaussian distribution and a set of features\n                for idx in range(max_label.astype(np.int_) + 1):\n\n                    # Obtaining the set of points belonging to the specific cluster\n                    wall_pps = dbscan_data[np.where(labels == idx)[0]]\n\n                    # Computing mean and covariance of the cluster\n                    mean_pps = np.mean(wall_pps, axis=0).reshape((3, 1))\n                    cov_pps = np.cov(wall_pps.T)\n\n                    # Skipping walls that do not meet the Atlanta world assumption\n                    if abs((pi / 2) - mean_pps[1]) > 0.25:\n                        continue\n\n                    # Changing the reference system of the Gaussian distribution: from robot to world frame\n                    mean_global, cov_global = self._pm.pps_from_robot_to_map(self._last_msg[5], mean_pps, cov_pps)\n\n                    # Too much uncertainty in the robot localization... Skipping data\n                    if mean_global is None:\n                        rospy.logwarn(\"Bad localization, skipping data...\")\n                        continue\n\n                    # Creating a dictionary with the characterization of the wall\n                    wall_dict = {\"mean\": mean_global.reshape((3,)), \"cov\": cov_global}\n\n                    # Obtaining the point cloud of the wall in Cartesian space\n                    wall_pcd = pcd_global.select_by_index(np.where(labels == idx)[0])\n                    _, inliers = wall_pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n                    wall_pcd = wall_pcd.select_by_index(inliers)\n\n                    # Remaining features of the wall\n                    wall_dict[\"n_samples\"] = np.asarray(wall_pcd.points).shape[0]\n                    wall_dict[\"n_detections\"] = 1\n                    wall_dict[\"max_bound\"] = wall_pcd.get_max_bound()\n                    wall_dict[\"min_bound\"] = wall_pcd.get_min_bound()\n                    wall_dict[\"color\"] = ColorRGBA(random.uniform(0, 1),random.uniform(0, 1),random.uniform(0, 1), 1.0)\n                    wall_dict[\"first_seen\"] = rospy.Time.now().to_sec()\n\n                    plane_width = np.sqrt((wall_dict[\"max_bound\"][0] - wall_dict[\"min_bound\"][0]) ** 2 +\n                                          (wall_dict[\"max_bound\"][1] - wall_dict[\"min_bound\"][1]) ** 2)\n\n                    plane_height = wall_dict[\"max_bound\"][2] - wall_dict[\"min_bound\"][2]\n\n                    # Extracting openings in walls\n                    opening_start = time.time()\n                    wall_dict[\"openings\"] = self._pm.detect_openings_in_plane(wall_dict, inv_tr_matrix,\n                                                                 self._last_msg[1], self._last_msg[2])\n\n                    self._time_opening_detection += time.time() - opening_start\n                    self._n_iterations_openings += 1\n\n                    # Accepting a wall if it has a minimum width... otherwise it is considered as non-informative\n                    if plane_width > self._min_plane_width and plane_height > self._min_plane_width:\n                        self._walls[str(self._num_walls)] = wall_dict\n                        self._num_walls += 1\n                    else:\n                        rospy.logwarn(\"Neglected because not sufficient width.\")\n\n                # Another clustering approach\n                matching_start = time.time()\n                order, plane_features = self._pm.plane_dict_to_features_comp(self._walls)\n\n                # Data association and integration process\n                new_walls, num_walls = self._pm.match_and_merge_planes(self._walls, plane_features, order,\n                                                                       self._pm.bhattacharyya_distance_features,\n                                                                       self._bhattacharyya_threshold,\n                                                                       self._euclidean_threshold)\n\n                self._time_plane_matching += time.time() - matching_start\n\n                # Updating the map\n                self._num_walls = num_walls\n                self._walls = {}\n                self._walls = new_walls\n\n                # Showing current floorplan\n                self._walls_pub.publish(self._pm.create_msg_walls_markers(self._walls))\n\n                # Print time information\n                try:\n                    loop_time = time.time() - time_start\n                    self._total_time += loop_time\n                    self._n_iterations += 1\n                    print(\"Loop time: \" + str(1000.0*loop_time) + \" ms / Mean Loop Time: \" +\n                          str(1000.0*self._total_time / self._n_iterations) + str(\" ms\"))\n                    print(\"Average plane extraction time: {:.2f} ms\".format(1000.0*self._time_plane_extraction / self._n_iterations))\n                    print(\"Average opening detection time: {:.2f} ms\".format(1000.0*self._time_opening_detection / self._n_iterations_openings))\n                    print(\"Average plane matching time: {:.2f} ms\".format(1000.0*self._time_plane_matching / self._n_iterations))\n                    print(\"Number of current planes: \" + str(self._num_walls))\n                except:\n                    pass\n                ###################################\n\n                self._flag_cnn = False\n                self._flag_processing = False\n\n            # CNN does not respond.\n            elif self._flag_processing and not self._flag_cnn:\n                # Skipping frame.\n                if self._tries > self._max_tries:\n                    self._flag_processing = False\n                    rospy.logwarn(\"[Sigma-FP] CNN does not respond, skipping frame.\")\n\n                # Awaiting CNN to process the last image\n                else:\n                    self._pub_processed_image.publish(self._bridge.cv2_to_imgmsg(self._last_msg[1], 'rgb8'))\n                    self._tries += 1\n\n            rate.sleep()\n\n    ####################################################################################################################\n    ##################################################### Callbacks ####################################################\n    ####################################################################################################################\n\n    def callback_synchronize_image(self, depth_msg, rgb_msg, pose_msg):\n        if not self._flag_processing:\n\n            if self.dataset == \"RobotAtVirtualHome\":\n                img_rgb = self.decode_image_rgb_from_unity(rgb_msg.data)\n                img_depth = self.decode_image_depth_from_unity(depth_msg.data)\n\n            elif self.dataset == \"RobotAtHome\":\n                img_rgb = self._bridge.imgmsg_to_cv2(rgb_msg, \"rgb8\")\n                img_depth = self._bridge.imgmsg_to_cv2(depth_msg, \"16UC1\")\n                img_rgb = cv2.rotate(img_rgb, cv2.ROTATE_90_COUNTERCLOCKWISE)\n                img_depth = np.divide(cv2.rotate(img_depth, cv2.ROTATE_90_COUNTERCLOCKWISE), 65535.0)\n\n            elif self.dataset == \"Giraff\":\n                img_rgb = self.decode_image_rgb_from_unity(rgb_msg.data)\n                img_depth = self._bridge.imgmsg_to_cv2(depth_msg)\n                img_depth = np.clip(img_depth, 0, 10.0)\n                img_depth = img_depth * 65535/10.0\n                img_depth = np.array(img_depth, dtype = np.uint16)\n                img_depth = np.divide(img_depth, 65535.0)\n\n            elif self.dataset == \"OpenLORIS\":\n                img_rgb = self._bridge.imgmsg_to_cv2(rgb_msg, \"rgb8\")\n                img_depth = self._bridge.imgmsg_to_cv2(depth_msg, \"16UC1\")\n                img_depth = img_depth.astype(np.float32)\n                img_depth = img_depth * 0.0001\n\n            else:\n                img_rgb = self._bridge.imgmsg_to_cv2(rgb_msg, \"rgb8\")\n                # Note that img_depth requires to be processed and normalized in range [0.0-1.0]\n                img_depth = np.divide(self._bridge.imgmsg_to_cv2(depth_msg, \"16UC1\"), 65535.0)\n\n            # Manual configuration of the Camera-Robot transform -> For custom dataset, please set the transform\n            # in the _camera_robot_transform variable as done in the examples.\n            try:\n                if self._camera_robot_transform is None:\n                    try:\n                        if self.dataset == \"Giraff\":\n                            self._camera_robot_transform = self._tfBuffer.lookup_transform('base_link',\n                                                                                           \"camera_down_link\",\n                                                                                           rospy.Time())\n                            self._camera_robot_transform.transform.rotation = Quaternion(0.0242788, -0.0703922, 0.0242788, 0.9969283)\n                            self._camera_robot_transform.transform.translation.x = -0.04\n                            self._camera_robot_transform.transform.translation.z = 0.9\n                        else:\n                            self._camera_robot_transform = self._tfBuffer.lookup_transform('base_link',\n                                                                                           rgb_msg.header.frame_id,\n                                                                                           rospy.Time())\n                        if self.dataset == \"RobotAtHome\":\n                            self._camera_robot_transform.transform.rotation = Quaternion(0.0, 0.0, 0.3826834, 0.9238795)\n                        elif self.dataset == \"OpenLORIS\":\n                            self._camera_robot_transform = self._tfBuffer.lookup_transform('base_link',\n                                                                                           depth_msg.header.frame_id,\n                                                                                           rospy.Time())\n                            self._camera_robot_transform.transform.rotation = Quaternion(0.0033077, 0.0080805, 0.0049632, 0.9999496)\n\n                    except:\n                        pass\n\n                self._last_msg = [rgb_msg.header, img_rgb, img_depth, None, None, pose_msg]\n                self._pub_processed_image.publish(self._bridge.cv2_to_imgmsg(img_rgb, 'rgb8'))\n                self._tries = 0\n\n                if self._start_time == 0:\n                    self._start_time = time.time()\n\n                if self._image_c is None and self._image_r is None:\n                    # Generate a meshgrid where each pixel contains its pixel coordinates\n                    self._height, self._width = img_depth.shape\n                    self._image_c, self._image_r = np.meshgrid(np.arange(self._width), np.arange(self._height),\n                                                               sparse=True)\n                    self._image_c = (self._cx - self._image_c) / self._fx\n                    self._image_r = (self._cy - self._image_r) / self._fy\n\n                if self._camera_robot_transform != None:\n                    self._flag_processing = True\n\n            except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException):\n                rospy.logwarn(\"Failing to retrieve robot pose\")\n\n    def callback_new_detection(self, result_cnn):\n\n        if self._flag_processing and not self._flag_cnn:\n            self._image_counter = self._image_counter + 1\n            if (self._image_counter % 11) == 10:\n                rospy.loginfo(\"Images detected per second=%.2f\",\n                              float(self._image_counter) / (time.time() - self._start_time))\n\n            if len(result_cnn.class_names) > 0 or np.max(np.max(self._bridge.imgmsg_to_cv2(result_cnn.walls))) > 0:\n                self._last_cnn_result = result_cnn\n                self._flag_cnn = True\n\n            else:\n                self._flag_processing = False\n\n    # This callback performs the Global Refinement Step. To run it, please publish a message in the /wallmap_commands\n    # topic.\n    def callback_commands(self, data):\n\n        command = data.data\n\n        if not os.path.exists(command) or command[0] != '/':\n            command = \"/home/jose/Escritorio/\"\n\n            # Another clustering approach\n            order, plane_features = self._pm.plane_dict_to_features_comp(self._walls)\n\n            new_walls, num_walls = self._pm.match_and_merge_planes(self._walls, plane_features, order,\n                                                                   self._pm.bhattacharyya_distance_features,\n                                                                   self._bhattacharyya_threshold,\n                                                                   self._euclidean_threshold)\n\n            self._num_walls = num_walls\n            self._walls = {}\n            self._walls = new_walls\n\n            # Saving Map\n            if command[0] == '/':\n                dir = command + \"wallmap_no_refined\" + \".npy\"\n\n                try:\n                    np.save(dir, self._walls)\n                    print(\"Map saved succesfully in \" + dir)\n                except:\n                    print(\"Error! Map cannot be saved in the given directory.\")\n\n            init_time_refinement = time.time()\n\n            self._walls = self._pm.global_refinement(self._walls)\n\n            print('Time for global refinement: ' + str(time.time() - init_time_refinement) + 'seconds')\n            self._walls_pub.publish(self._pm.create_msg_walls_markers(self._walls))\n\n            dir = command + \"wallmap_refined\" + \".npy\"\n\n            try:\n                np.save(dir, self._walls)\n                print(\"Refined Map saved succesfully in \" + dir)\n            except:\n                pass\n\n    ####################################################################################################################\n    ################################################### Static Methods #################################################\n    ####################################################################################################################\n\n    @staticmethod\n    def load_param(param, default=None):\n        new_param = rospy.get_param(param, default)\n        rospy.loginfo(\"[Sigma-FP] %s: %s\", param, new_param)\n        return new_param\n\n    @staticmethod\n    def decode_image_rgb_from_unity(unity_img):\n        np_arr = np.frombuffer(unity_img, np.uint8)\n        im = cv2.imdecode(np_arr, -1)\n        img_rgb = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n\n        return img_rgb\n\n    @staticmethod\n    def decode_image_depth_from_unity(unity_img):\n        buf = np.ndarray(shape=(1, len(unity_img)),\n                         dtype=np.uint8, buffer=unity_img)\n        img_depth = cv2.imdecode(buf, cv2.IMREAD_UNCHANGED)\n        img_depth = np.divide(img_depth, 65535.0)\n\n        return img_depth\n\n\n########################################################################################################################\n######################################################### Main #########################################################\n########################################################################################################################\n\ndef main(argv):\n    rospy.init_node('3D-Floorplan-Reconstruction')\n    node = FloorplanReconstruction()\n    node.run()\n\n\nif __name__ == '__main__':\n    main(sys.argv)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/fast-sigma-FP.py b/src/fast-sigma-FP.py
--- a/src/fast-sigma-FP.py	(revision dd746d9985842c586d4b7196e0be9d32dfdf3a39)
+++ b/src/fast-sigma-FP.py	(date 1671438831474)
@@ -236,6 +236,8 @@
 
                 # DBSCAN Clustering
                 clustering = DBSCAN(eps=1., min_samples=self._min_points_plane).fit(dbscan_data_scaled)
+                #clustering contiene i piani principali che formano le pareti e quindi si pu√≤ prendere l'orientation
+                # e poi raddrizzarli.
                 labels = clustering.labels_.astype(np.float_)
                 max_label = labels.max()
 
